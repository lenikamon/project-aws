{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd7002cd",
   "metadata": {},
   "source": [
    "# Creaci√≥n y Despliegue de un Sistema RAG con Gemini en AWS SageMaker\n",
    "\n",
    "\n",
    "Este notebook detalla el proceso completo para construir, desplegar y probar un sistema de **Generaci√≥n Aumentada por Recuperaci√≥n (RAG)**. El sistema utiliza el modelo **Gemini de Google** y se despliega como un endpoint en **AWS SageMaker**.\n",
    "\n",
    "\n",
    "## Flujo de Trabajo\n",
    "\n",
    "El proceso se divide en los siguientes pasos clave:\n",
    "\n",
    "1.  **Preparaci√≥n del Entorno**: Instalaci√≥n de dependencias y carga de variables de entorno (como la clave de API de Gemini y el nombre del bucket de S3).\n",
    "2.  **Limpieza de Datos**: Procesamiento y limpieza de documentos de texto fuente para prepararlos para la ingesta.\n",
    "3.  **Creaci√≥n del RAG Local**:\n",
    "    *   Generaci√≥n de embeddings a partir de los documentos limpios.\n",
    "    *   Creaci√≥n de una base de datos vectorial con **ChromaDB**.\n",
    "    *   Prueba del sistema RAG en el entorno local del notebook para validar la l√≥gica.\n",
    "4.  **Empaquetado para Despliegue**: Creaci√≥n de los artefactos necesarios para el endpoint de SageMaker, incluyendo el script de inferencia (`inference.py`) y las dependencias (`requirements.txt`).\n",
    "5.  **Despliegue en SageMaker**:\n",
    "    *   Subida de los artefactos del modelo a un bucket de S3.\n",
    "    *   Creaci√≥n y despliegue de un **Hugging Face Model** en SageMaker, que act√∫a como un proxy para realizar llamadas a la API de Gemini.\n",
    "6.  **Prueba del Endpoint**: Invocaci√≥n del endpoint desplegado a trav√©s de una API Gateway para verificar su funcionamiento en un entorno real."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b38584f",
   "metadata": {},
   "source": [
    "## Crear RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9c1ec3c9-f772-403c-8e6b-84eba9e2bfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Instalaci√≥n de dependencias completa.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install \"transformers==4.38.2\" \"accelerate==0.27.2\" \"sentence-transformers==2.5.1\" \"langchain==0.1.12\" \"langchain-community==0.0.28\" \"chromadb>=0.5.0\" \"pysqlite3-binary\" \"numpy<2.0\" -q\n",
    "\n",
    "!pip install google-genai -q\n",
    "\n",
    "!pip install dotenv -q\n",
    "\n",
    "print(\"‚úÖ Instalaci√≥n de dependencias completa.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ab61ed-bc92-4192-bdd1-4971fdd8c534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Variables cargadas. Bucket objetivo: sagemaker-us-east-1-891377282708\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv \n",
    "\n",
    "!pip install python-dotenv -q\n",
    "\n",
    "load_dotenv('var.env') \n",
    "\n",
    "# 3. Recuperar las variables para usarlas en el script de despliegue\n",
    "GEMINI_KEY_VALUE = os.environ.get(\"GEMINI_API_KEY\")\n",
    "BUCKET_NAME = os.environ.get(\"S3_BUCKET_NAME\")\n",
    "\n",
    "if not GEMINI_KEY_VALUE:\n",
    "    raise ValueError(\"‚ùå ERROR: La clave GEMINI_API_KEY no se carg√≥. Revisa tu archivo vars.env.\")\n",
    "\n",
    "print(f\"‚úÖ Variables cargadas. Bucket objetivo: {BUCKET_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fc4b6f0-25c7-486b-b9c8-022142d6004c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ EJECUTANDO LIMPIEZA V5 (Anti-CSS) en 39 archivos...\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "üéâ ¬°Limpieza terminada! Revisa la carpeta 'Clean_Text'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import html\n",
    "\n",
    "# --- 1. CONFIGURACI√ìN ---\n",
    "input_folder = 'texts'\n",
    "output_folder = 'Clean_Text'\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# --- 2. FUNCI√ìN DE LIMPIEZA V5 (Anti-CSS y Men√∫s) ---\n",
    "def limpieza_v5_final(texto):\n",
    "    if not texto: return \"\"\n",
    "\n",
    "    # A. PRIMERA PASADA: Limpieza global\n",
    "    texto = html.unescape(texto)\n",
    "    texto = re.sub(r'/\\*.*?\\*/', '', texto, flags=re.DOTALL) # Comentarios /* ... */\n",
    "    \n",
    "    lineas = texto.split('\\n')\n",
    "    lineas_limpias = []\n",
    "    \n",
    "    lista_negra_exacta = [\n",
    "        \"Skip to content\", \"Top Menu\", \"Top Men√∫\", \"Main Menu\", \"MEN√ö\",\n",
    "        \"Inicio\", \"UNISON\", \"DEPARTAMENTO\", \"FACULTAD\",\n",
    "        \"ACERCA DEL PROGRAMA\", \"INFORMACI√ìN PARA ALUMNOS\", \"ADMISI√ìN\",\n",
    "        \"DOCENTES\", \"EDITORIAL\", \"NOTICIAS Y AVISOS\", \n",
    "        \"NOTICIAS Y AVISOS ANTERIORES\", \"Previous\", \"Next\",\n",
    "        \"Con√≥cenos\", \"Misi√≥n  y Visi√≥n\", \"Plan de Estudios\", \"Requisitos\",\n",
    "        \"Egreso\", \"Titulaci√≥n\", \"Idioma\", \"Servicio Social\", \"CENEVAL\",\n",
    "        \"Culturest\", \"Pr√°cticas  Profesionales\", \"Programa\", \"Alumnos\",\n",
    "        \"Ingreso\", \"Plan de Estudios 2025-2\", \"Plan de Estudios 2005-2\",\n",
    "        \"Tesis\", \"Reestructuraci√≥n LCC\", \"Licenciatura en Ciencias de la Computaci√≥n\",\n",
    "        \"AI-Linkup\", \"Banner Reestructuraci√≥n LCC\", \"25 Aniversario LCC\",\n",
    "        \"Departamento de Matem√°ticas\", \"Universidad de Sonora\",\n",
    "        \"Presentaci√≥n\", \"Directorio\", \"Trayectorias Escolares\", \"LCC-HUB\", \"Tutor√≠as\"\n",
    "        \"-->\" \n",
    "    ]\n",
    "    \n",
    "    # INDICADORES DE C√ìDIGO (Si la l√≠nea TIENE esto, SE BORRA)\n",
    "    indicadores_codigo = [\n",
    "        # HTML/JS\n",
    "        \"body{\", \"img.emoji\", \"img.wp-smiley\", \".recentcomments\", \n",
    "        \"!function\", \"window._wpemoji\", \"var \", \"$(document)\", \"$(\\\"#\", \n",
    "        \"owlCarousel\", \"function() {\", \"});\",\n",
    "        # CSS (Aqu√≠ estaba el problema, agregamos las propiedades)\n",
    "        \"!important\", \"box-shadow:\", \"height:\", \"width:\", \"margin:\", \n",
    "        \"vertical-align:\", \"padding:\", \"display:\", \"border:\", \"background:\",\n",
    "        \".wp-block-\", \".has-\"\n",
    "        \"autoPlay:\", \"items :\", \"itemsDesktop\", \"itemsDesktopSmall\", \"//Set AutoPlay\"\n",
    "    ]\n",
    "\n",
    "    for linea in lineas:\n",
    "        linea_strip = linea.strip()\n",
    "        \n",
    "        # 1. Vac√≠o\n",
    "        if not linea_strip:\n",
    "            continue\n",
    "        \n",
    "        # 2. Regla Anti-C√≥digo (CSS/JS)\n",
    "        es_codigo = False\n",
    "        \n",
    "        # 2.1 Verificar si contiene palabras prohibidas de c√≥digo\n",
    "        for ind in indicadores_codigo:\n",
    "            if ind in linea_strip: \n",
    "                es_codigo = True\n",
    "                break\n",
    "        \n",
    "        # 2.2 Verificar sintaxis t√©cnica (llaves sueltas)\n",
    "        if \"{\" in linea_strip and \"}\" not in linea_strip: \n",
    "             if len(linea_strip) < 60: es_codigo = True\n",
    "        \n",
    "        if linea_strip == \"});\" or linea_strip == \"}\" or linea_strip == \"-->\":\n",
    "            es_codigo = True\n",
    "\n",
    "        if es_codigo:\n",
    "            continue\n",
    "\n",
    "        # 3. Regla Lista Negra (Men√∫s y Pies de p√°gina)\n",
    "        es_basura_menu = False\n",
    "        \n",
    "        # 3.1 Detecci√≥n de pie de p√°gina largo con barras \"|\"\n",
    "        if \"Universidad de Sonora\" in linea_strip and \"|\" in linea_strip:\n",
    "            es_basura_menu = True\n",
    "\n",
    "        # 3.2 Detecci√≥n de frases exactas\n",
    "        if not es_basura_menu:\n",
    "            for basura in lista_negra_exacta:\n",
    "                # Coincidencia exacta\n",
    "                if linea_strip.lower() == basura.lower():\n",
    "                    es_basura_menu = True\n",
    "                    break\n",
    "                # Contenida (para l√≠neas cortas)\n",
    "                if basura.lower() in linea_strip.lower() and len(linea_strip) < len(basura) + 5:\n",
    "                    es_basura_menu = True\n",
    "                    break\n",
    "        \n",
    "        if es_basura_menu:\n",
    "            continue\n",
    "            \n",
    "        # 4. Regla de longitud m√≠nima para basura suelta\n",
    "        #    Borra l√≠neas de menos de 3 letras si no son n√∫meros o letras\n",
    "        if len(linea_strip) < 3 and not linea_strip[0].isalnum():\n",
    "            continue\n",
    "\n",
    "        # SI SOBREVIVI√ì, GUARDAR\n",
    "        lineas_limpias.append(linea_strip)\n",
    "\n",
    "    # C. RECONSTRUCCI√ìN Y DETALLES FINALES\n",
    "    texto_final = \"\\n\".join(lineas_limpias)\n",
    "    texto_final = re.sub(r'\\n{3,}', '\\n\\n', texto_final) # Maximo 2 enters\n",
    "    \n",
    "    return texto_final\n",
    "\n",
    "# --- 3. EJECUCI√ìN ---\n",
    "try:\n",
    "    archivos = [f for f in os.listdir(input_folder) if f.endswith('.txt')]\n",
    "    print(f\"üßπ EJECUTANDO LIMPIEZA V5 (Anti-CSS) en {len(archivos)} archivos...\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    count = 0\n",
    "    for filename in archivos:\n",
    "        path_origen = os.path.join(input_folder, filename)\n",
    "        path_destino = os.path.join(output_folder, filename)\n",
    "        \n",
    "        try:\n",
    "            with open(path_origen, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                contenido = f.read()\n",
    "            \n",
    "            limpio = limpieza_v5_final(contenido)\n",
    "            \n",
    "            if len(limpio) > 30:\n",
    "                with open(path_destino, 'w', encoding='utf-8') as f:\n",
    "                    f.write(limpio)\n",
    "                count += 1\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Archivo qued√≥ vac√≠o: {filename}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error en {filename}: {e}\")\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"üéâ ¬°Limpieza terminada! Revisa la carpeta '{output_folder}'.\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Error: No existe la carpeta 'texts'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b4c02d-dda1-48d5-a31e-1ac44828863a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"GEMINI_API_KEY\"] = \"tu_clave_aqui\"  # Reemplaza con tu clave real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c859e7-3865-43f0-8bde-6bbd4a840f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Cargando Clean_Text y generando Embeddings...\n",
      "‚úÖ Base de Datos ChromaDB lista.\n",
      "‚úÖ Cliente Gemini gemini-2.5-flash inicializado.\n",
      "\n",
      "‚ùì ¬øQui√©n es el responsable de tutor√≠as?\n",
      "üîç Buscando contexto en ChromaDB...\n",
      "üí° R: Dr. Edelmira Rodr√≠guez Alcantar.\n",
      "‚è±Ô∏è Tiempo total RAG (Contexto + API): 1.41 segundos\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- 1. CONFIGURACI√ìN E IMPORTS ---\n",
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
    "import os\n",
    "import time\n",
    "from google import genai\n",
    "from google.genai import types # Importamos types para la configuraci√≥n\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# --- 2. CARGAR DOCUMENTOS Y EMBEDDINGS ---\n",
    "print(\"üìÇ Cargando Clean_Text y generando Embeddings...\")\n",
    "loader = DirectoryLoader('./Clean_Text', glob=\"*.txt\", loader_cls=TextLoader)\n",
    "docs_raw = loader.load()\n",
    "\n",
    "if docs_raw:\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=300)\n",
    "    docs = text_splitter.split_documents(docs_raw)\n",
    "    \n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "    db = Chroma.from_documents(docs, embeddings)\n",
    "    print(\"‚úÖ Base de Datos ChromaDB lista.\")\n",
    "\n",
    "\n",
    "    try:\n",
    "        gemini_client = genai.Client()\n",
    "        MODEL_NAME = 'gemini-2.5-flash'\n",
    "        print(f\"‚úÖ Cliente Gemini {MODEL_NAME} inicializado.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR: No se pudo iniciar el cliente Gemini. Revisa tu clave API.\")\n",
    "        raise e\n",
    "\n",
    "    # --- 4. FUNCI√ìN DE PREGUNTA (USANDO GEMINI) ---\n",
    "    def preguntar_gemini(pregunta_usuario):\n",
    "        start_time = time.time()\n",
    "        print(f\"\\n‚ùì {pregunta_usuario}\")\n",
    "        print(\"üîç Buscando contexto en ChromaDB...\")\n",
    "        \n",
    "        docs_encontrados = db.similarity_search(pregunta_usuario, k=7)\n",
    "        contexto_acumulado = \"\"\n",
    "        \n",
    "        for doc in docs_encontrados:\n",
    "            nombre = doc.metadata.get('source', 'unknown').split('/')[-1]\n",
    "            clean_content = doc.page_content.replace('\\n', ' ').strip()\n",
    "            contexto_acumulado += f\"- [Archivo: {nombre}] {clean_content}\\n\\n\"\n",
    "\n",
    "        # Prompt con reglas para la API de Gemini\n",
    "        prompt_final = f\"\"\"<|im_start|>system\n",
    "Eres un asistente administrativo √∫til. Responde de forma muy concisa usando SOLO el siguiente contexto.\n",
    "Reglas:\n",
    "1. Responde usando SOLO el contexto.\n",
    "3. Si la respuesta no est√°, di \"No tengo informaci√≥n.\"\n",
    "<|im_end|>\n",
    "<|im_start|>user\n",
    "Contexto:\\n{contexto_acumulado}\\n\\nPregunta: {pregunta_usuario}\n",
    "<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # Generar Respuesta con la API de Gemini\n",
    "            response = gemini_client.models.generate_content(\n",
    "                model=MODEL_NAME,\n",
    "                contents=[prompt_final],\n",
    "                config=types.GenerateContentConfig(temperature=0.01)\n",
    "            )\n",
    "\n",
    "            respuesta_limpia = response.text.strip()\n",
    "            end_time = time.time()\n",
    "            \n",
    "            print(\"üí° R:\", respuesta_limpia)\n",
    "            print(f\"‚è±Ô∏è Tiempo total RAG (Contexto + API): {end_time - start_time:.2f} segundos\")\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error API: {e}\")\n",
    "            \n",
    "    # --- 5. PRUEBAS ---\n",
    "    preguntar_gemini(\"¬øQui√©n es el responsable de tutor√≠as?\")\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Carpeta vac√≠a.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8277c2c-3775-404b-9f92-0925934a7f78",
   "metadata": {},
   "source": [
    "## Subir al EndPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "491f8174-82cd-454a-91dc-07aa0386f0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Directorio de trabajo creado: model_deploy/code\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define la ruta base para el despliegue\n",
    "DEPLOY_DIR = 'model_deploy/code'\n",
    "\n",
    "# Elimina el directorio anterior si existe y crea uno nuevo limpio\n",
    "!rm -rf model_deploy\n",
    "!mkdir -p {DEPLOY_DIR}\n",
    "\n",
    "print(f\"‚úÖ Directorio de trabajo creado: {DEPLOY_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f42fd1b8-8ba9-47ae-acb6-e3f16794f4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_deploy/code/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_deploy/code/requirements.txt\n",
    "transformers==4.38.2\n",
    "accelerate==0.27.2\n",
    "sentence-transformers==2.5.1\n",
    "langchain==0.1.12\n",
    "langchain-community==0.0.28\n",
    "chromadb>=0.5.0\n",
    "pysqlite3-binary\n",
    "numpy<2.0\n",
    "google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f363ba90-1d11-422e-9316-d86c3e3c15d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_deploy/code/inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_deploy/code/inference.py\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import zipfile\n",
    "import shutil\n",
    "import time \n",
    "from google import genai\n",
    "from google.genai import types \n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
    "\n",
    "GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY') \n",
    "BUCKET_NAME = os.environ.get('S3_BUCKET', 'sagemaker-us-east-1-891377282708')\n",
    "DB_ZIP_KEY = os.environ.get('DB_ZIP_KEY', 'rag-artifacts/chroma_db.zip')\n",
    "EXTRACT_PATH = '/tmp/chroma_db'\n",
    "MODEL_NAME = 'gemini-2.5-flash' # Modelo r√°pido\n",
    "\n",
    "db_client = None \n",
    "gemini_client = None\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Inicializa la DB ChromaDB y el cliente Gemini (se ejecuta 1 vez).\"\"\"\n",
    "    global db_client, gemini_client\n",
    "    print(\"üöÄ [Start] Iniciando Proxy Gemini en SageMaker...\")\n",
    "    \n",
    "    if not GEMINI_API_KEY:\n",
    "        raise EnvironmentError(\"GEMINI_API_KEY no configurada. ¬°Revisa las variables de entorno del despliegue!\")\n",
    "\n",
    "    # 1. Descargar y Cargar DB Chroma\n",
    "    s3_client = boto3.client('s3')\n",
    "    local_zip_path = '/tmp/chroma_db.zip'\n",
    "\n",
    "    if os.path.exists(EXTRACT_PATH):\n",
    "        shutil.rmtree(EXTRACT_PATH)\n",
    "    os.makedirs(EXTRACT_PATH, exist_ok=True)\n",
    "    \n",
    "    s3_client.download_file(BUCKET_NAME, DB_ZIP_KEY, local_zip_path)\n",
    "    with zipfile.ZipFile(local_zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(EXTRACT_PATH)\n",
    "    \n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "    db_client = Chroma(persist_directory=EXTRACT_PATH, embedding_function=embeddings)\n",
    "    \n",
    "    # 2. Inicializar Cliente Gemini\n",
    "    gemini_client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "    \n",
    "    print(\"‚úÖ [Ready] Sistema RAG con Proxy Gemini listo.\")\n",
    "    return {\"db\": db_client, \"gemini_client\": gemini_client}\n",
    "\n",
    "\n",
    "def predict_fn(data, context):\n",
    "    \"\"\"Ejecuta la b√∫squeda RAG y llama a Gemini (se ejecuta en cada invocaci√≥n).\"\"\"\n",
    "    \n",
    "    # 1. Recuperar artefactos\n",
    "    db = context[\"db\"]\n",
    "    gemini = context[\"gemini_client\"]\n",
    "\n",
    "    # 2. Leer la pregunta del payload\n",
    "    if isinstance(data, list):\n",
    "        input_data = data[0]\n",
    "    else:\n",
    "        input_data = data\n",
    "        \n",
    "    # 'inputs' es la clave que env√≠a tu Lambda\n",
    "    pregunta = input_data.get('inputs', input_data.get('question', '')) \n",
    "    \n",
    "    if not pregunta:\n",
    "        raise ValueError(\"Pregunta vac√≠a recibida.\")\n",
    "        \n",
    "    # 3. RAG: B√∫squeda de contexto (K=3, para velocidad)\n",
    "    docs_encontrados = db.similarity_search(pregunta, k=3)\n",
    "    contexto_acumulado = \"\\n\".join([doc.page_content.replace('\\n', ' ').strip() for doc in docs_encontrados])\n",
    "    \n",
    "    # 4. Prompt para Gemini\n",
    "    prompt_final = f\"\"\"<|im_start|>system\n",
    "Eres un asistente administrativo √∫til. Responde de forma muy concisa usando SOLO el siguiente contexto.\n",
    "Reglas:\n",
    "1. Responde usando SOLO el contexto.\n",
    "3. Si la respuesta no est√°, di \"No tengo informaci√≥n.\"\n",
    "<|im_end|>\n",
    "<|im_start|>user\n",
    "Contexto:\\n{contexto_acumulado}\\n\\nPregunta: {pregunta}\n",
    "<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "    \n",
    "    response = gemini.models.generate_content(\n",
    "        model=MODEL_NAME,\n",
    "        contents=[prompt_final],\n",
    "        config=types.GenerateContentConfig(temperature=0.01)\n",
    "    )\n",
    "    \n",
    "    texto_respuesta = response.text.strip()\n",
    "    \n",
    "    # 6. Devolver en el formato esperado por la Lambda (lista de dicts con 'generated_text')\n",
    "    return [{\"generated_text\": texto_respuesta}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2afe78b1-d19c-46d9-84c2-fcbd909b811d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Creando paquete final del Proxy Gemini...\n",
      "code/\n",
      "code/requirements.txt\n",
      "code/inference.py\n",
      "‚úÖ Paquete de c√≥digo subido a: s3://sagemaker-us-east-1-891377282708/rag-code-proxy/model_proxy.tar.gz\n",
      "üöÄ LANZANDO ENDPOINT PROXY...\n",
      "--------!--------------------------------------------------\n",
      "‚úÖ ¬°LISTO! Tu nuevo Endpoint Proxy es: gemini-proxy-20251206-231118\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from dotenv import load_dotenv # Necesario si no se ejecut√≥ antes\n",
    "\n",
    "# --- 1. CARGAR VARIABLES (USANDO os.environ) ---\n",
    "# Aseg√∫rate de que tu archivo 'vars.env' est√© en el mismo directorio.\n",
    "if 'GEMINI_API_KEY' not in os.environ:\n",
    "    load_dotenv('vars.env')\n",
    "\n",
    "GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\") \n",
    "BUCKET_NAME = os.environ.get(\"S3_BUCKET_NAME\", 'sagemaker-us-east-1-891377282708')\n",
    "\n",
    "if not GEMINI_API_KEY:\n",
    "    raise ValueError(\"‚ùå ERROR: La clave GEMINI_API_KEY no se carg√≥. Crea y verifica tu archivo vars.env.\")\n",
    "\n",
    "ENDPOINT_NAME = f'gemini-proxy-{time.strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "\n",
    "# --- 2. EMPAQUETAR Y SUBIR ---\n",
    "print(\"üì¶ Creando paquete final del Proxy Gemini...\")\n",
    "\n",
    "# Nota: Aseg√∫rate de que las celdas %%writefile hayan creado la carpeta model_deplo/code\n",
    "!cd model_deploy && tar -czvf ../model_proxy.tar.gz code\n",
    "\n",
    "# Subir el paquete a S3\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "model_uri = sess.upload_data(path='model_proxy.tar.gz', bucket=BUCKET_NAME, key_prefix='rag-code-proxy')\n",
    "\n",
    "print(f\"‚úÖ Paquete de c√≥digo subido a: {model_uri}\")\n",
    "\n",
    "\n",
    "# --- 3. DESPLEGAR ENDPOINT PROXY ---\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    model_data=model_uri,\n",
    "    role=role,\n",
    "    # Estos valores son necesarios para el contenedor base HuggingFace\n",
    "    transformers_version=\"4.37.0\",\n",
    "    pytorch_version=\"2.1.0\",\n",
    "    py_version=\"py310\",\n",
    "    # CR√çTICO: INYECTAR LAS VARIABLES DE ENTORNO\n",
    "    env={ \n",
    "        'GEMINI_API_KEY': GEMINI_API_KEY, # La clave se inyecta de forma segura\n",
    "        'S3_BUCKET': BUCKET_NAME,\n",
    "        'DB_ZIP_KEY': 'rag-artifacts/chroma_db.zip',\n",
    "        'HF_TASK': 'text-generation',\n",
    "        'SAGEMAKER_MODEL_SERVER_WORKERS': '1',\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"üöÄ LANZANDO ENDPOINT PROXY...\")\n",
    "try:\n",
    "    predictor = huggingface_model.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type=\"ml.m5.xlarge\", \n",
    "        endpoint_name=ENDPOINT_NAME\n",
    "    )\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(f\"‚úÖ ¬°LISTO! Tu nuevo Endpoint Proxy es: {predictor.endpoint_name}\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error al desplegar el Endpoint: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd18985",
   "metadata": {},
   "source": [
    "# Llamar Lambda para probar funcionamiento del endpoint y RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c82b322c-513f-4623-80dd-3c889853d939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì° Probando API Gateway con Proxy Gemini: https://7cfazo47r0.execute-api.us-east-1.amazonaws.com/default/RAG_Backend\n",
      "‚è≥ Pregunta: '¬øQui√©n es el responsable de tutor√≠as y cu√°les son todos los requisitos de idioma para titulaci√≥n?'\n",
      "------------------------------------------------------------\n",
      "‚úÖ ¬°√âXITO! Respuesta en 3.41 segundos.\n",
      "--------------------------------------------------\n",
      "Respuesta Final:\n",
      "El responsable del programa de tutor√≠as en la Licenciatura en Ciencias de la Computaci√≥n es la Dra. Edelmira Rodr√≠guez Alcantar.\n",
      "\n",
      "Los requisitos de idioma para titulaci√≥n son:\n",
      "*   Acreditar el nivel IV de ingl√©s en el Departamento de Lenguas Extranjeras.\n",
      "*   Acreditar el curso Comprensi√≥n de Lectura 1 del Departamento de Lenguas Extranjeras.\n",
      "*   Acreditar la obtenci√≥n de al menos 320 puntos en el examen TOEFL.\n",
      "*   Acreditar una estancia internacional en idioma ingl√©s de tres meses como m√≠nimo.\n",
      "*   Acreditar estudios escolarizados concluidos, realizados en idioma ingl√©s, equivalentes a los niveles de educaci√≥n b√°sica y media superior.\n",
      "*   Acreditar al menos una asignatura de nivel superior, cursada y aprobada, en idioma ingl√©s.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import requests\n",
    "from requests.exceptions import Timeout\n",
    "\n",
    "# --- CONFIGURACI√ìN ---\n",
    "API_GATEWAY_URL = \"https://7cfazo47r0.execute-api.us-east-1.amazonaws.com/default/RAG_Backend\"\n",
    "\n",
    "# El timeout de requests.post es el tiempo que el cliente esperar√° (ponemos 29s por si acaso)\n",
    "CLIENT_TIMEOUT = 29 \n",
    "\n",
    "# Pregunta compleja que fallaba antes\n",
    "pregunta_final = \"¬øQui√©n es el responsable de tutor√≠as y cu√°les son todos los requisitos de idioma para titulaci√≥n?\"\n",
    "\n",
    "# Payload de la Web (usa 'question' o 'inputs')\n",
    "payload = {\n",
    "    \"question\": pregunta_final\n",
    "}\n",
    "\n",
    "print(f\"üì° Probando API Gateway con Proxy Gemini: {API_GATEWAY_URL}\")\n",
    "print(f\"‚è≥ Pregunta: '{pregunta_final}'\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Hacemos la petici√≥n como si fu√©ramos la p√°gina web\n",
    "    response = requests.post(\n",
    "        API_GATEWAY_URL, \n",
    "        json=payload, \n",
    "        timeout=CLIENT_TIMEOUT\n",
    "    )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Intenta decodificar el JSON de la respuesta\n",
    "    try:\n",
    "        result = response.json()\n",
    "    except json.JSONDecodeError:\n",
    "        result = {\"answer\": f\"Respuesta no JSON: {response.text[:100]}...\"}\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        print(f\"‚úÖ ¬°√âXITO! Respuesta en {end_time - start_time:.2f} segundos.\")\n",
    "        print(\"--------------------------------------------------\")\n",
    "        print(f\"Respuesta Final:\\n{result.get('answer', 'Respuesta inesperada')}\")\n",
    "    else:\n",
    "        print(f\"‚ùå FALLO DE SERVIDOR/PROXY: Status Code {response.status_code}\")\n",
    "        print(f\"Detalle del error: {result.get('error', 'Error no detallado.')}\")\n",
    "        \n",
    "except Timeout:\n",
    "    # Este error solo deber√≠a ocurrir si todo el proceso tarda > 29s, lo cual ya no deber√≠a pasar\n",
    "    print(f\"‚ùå ERROR: Timeout (L√≠mite de 29s alcanzado). El Proxy de Gemini Fall√≥ o el Endpoint no est√° activo.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERROR DE CONEXI√ìN: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
